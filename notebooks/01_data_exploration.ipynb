{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768735b8",
   "metadata": {},
   "source": [
    "# Store Sales STGAT Project - Phase 1: Data Foundation Implementation\n",
    "\n",
    "**Objective**: Data-driven evaluation case selection for Corporaci√≥n Favorita retail forecasting\n",
    "\n",
    "**Key Goals**:\n",
    "- Comprehensive data exploration and quality assessment\n",
    "- Data-driven selection of 10 evaluation cases (not arbitrary combinations)\n",
    "- Establish quality-based evaluation framework\n",
    "- Create production-ready data modules\n",
    "\n",
    "**Methodology**: Multi-criteria selection ensuring statistical validity and pattern diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34e5b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Store Sales STGAT Project - Phase 1: Data Foundation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('src/data', exist_ok=True)\n",
    "\n",
    "print(\"üìä Store Sales STGAT Project - Phase 1: Data Foundation\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3fe85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4551a",
   "metadata": {},
   "outputs": [],
   "source": "class FavoritaDataExplorer:\n    \"\"\"\n    Comprehensive data exploration and quality assessment for Corporaci√≥n Favorita dataset\n    \n    Features:\n    - Systematic data quality evaluation\n    - Store-family combination analysis\n    - Data-driven case selection algorithm\n    - Production-ready evaluation case management\n    \"\"\"\n    \n    def __init__(self, data_path='../data/raw', results_path='../results/'):\n        self.data_path = data_path\n        self.results_path = results_path\n        self.sales_data = None\n        self.stores_data = None\n        self.oil_data = None\n        self.holidays_data = None\n        self.combination_metrics = None\n        self.selected_cases = None\n        \n        print(f\"üîß Initialized FavoritaDataExplorer\")\n        print(f\"   Data path: {data_path}\")\n        print(f\"   Results path: {results_path}\")\n    \n    def load_datasets(self):\n        \"\"\"Load all Corporaci√≥n Favorita datasets with comprehensive validation\"\"\"\n        print(\"\\nüìÅ Loading Corporaci√≥n Favorita datasets...\")\n        \n        try:\n            # Load primary datasets\n            self.sales_data = pd.read_csv(f'{self.data_path}/train.csv')\n            self.stores_data = pd.read_csv(f'{self.data_path}/stores.csv')\n            self.oil_data = pd.read_csv(f'{self.data_path}/oil.csv')\n            self.holidays_data = pd.read_csv(f'{self.data_path}/holidays_events.csv')\n            \n            # Convert date columns\n            self.sales_data['date'] = pd.to_datetime(self.sales_data['date'])\n            self.oil_data['date'] = pd.to_datetime(self.oil_data['date'])\n            self.holidays_data['date'] = pd.to_datetime(self.holidays_data['date'])\n            \n            # Display dataset overview\n            print(f\"‚úÖ Sales data: {len(self.sales_data):,} records\")\n            print(f\"   ‚Ä¢ Date range: {self.sales_data['date'].min()} to {self.sales_data['date'].max()}\")\n            print(f\"   ‚Ä¢ Stores: {self.sales_data['store_nbr'].nunique()}\")\n            print(f\"   ‚Ä¢ Product families: {self.sales_data['family'].nunique()}\")\n            print(f\"   ‚Ä¢ Total days: {(self.sales_data['date'].max() - self.sales_data['date'].min()).days}\")\n            \n            print(f\"‚úÖ Stores metadata: {len(self.stores_data)} stores\")\n            print(f\"‚úÖ Oil prices: {len(self.oil_data)} records\")\n            print(f\"‚úÖ Holidays data: {len(self.holidays_data)} events\")\n            \n            return True\n            \n        except Exception as e:\n            print(f\"‚ùå Error loading datasets: {e}\")\n            print(\"üìã Expected files in data/raw/:\")\n            print(\"   ‚Ä¢ train.csv (sales data)\")\n            print(\"   ‚Ä¢ stores.csv (store metadata)\")\n            print(\"   ‚Ä¢ oil.csv (oil prices)\")\n            print(\"   ‚Ä¢ holidays_events.csv (holidays)\")\n            return False\n\n    # Additional methods will be added in subsequent cells..."
  },
  {
   "cell_type": "markdown",
   "id": "0fb4f15b",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec59b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_data_assessment(self):\n",
    "    \"\"\"\n",
    "    Systematic data quality evaluation for academic rigor\n",
    "    \n",
    "    Returns comprehensive quality metrics for case selection\n",
    "    \"\"\"\n",
    "    print(\"\\nüîç Comprehensive Data Quality Assessment\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if self.sales_data is None:\n",
    "        print(\"‚ùå Please load datasets first using load_datasets()\")\n",
    "        return None\n",
    "    \n",
    "    # Core data quality metrics\n",
    "    quality_metrics = {\n",
    "        'dataset_overview': {\n",
    "            'total_records': len(self.sales_data),\n",
    "            'date_range': {\n",
    "                'start': self.sales_data['date'].min(),\n",
    "                'end': self.sales_data['date'].max(),\n",
    "                'total_days': (self.sales_data['date'].max() - self.sales_data['date'].min()).days\n",
    "            },\n",
    "            'stores_count': self.sales_data['store_nbr'].nunique(),\n",
    "            'families_count': self.sales_data['family'].nunique(),\n",
    "            'unique_combinations': self.sales_data.groupby(['store_nbr', 'family']).ngroups\n",
    "        },\n",
    "        \n",
    "        'data_quality': {\n",
    "            'missing_values': self.sales_data.isnull().sum().to_dict(),\n",
    "            'zero_sales_records': (self.sales_data['sales'] == 0).sum(),\n",
    "            'zero_sales_percentage': (self.sales_data['sales'] == 0).mean() * 100,\n",
    "            'negative_sales': (self.sales_data['sales'] < 0).sum(),\n",
    "            'sales_statistics': self.sales_data['sales'].describe().to_dict()\n",
    "        },\n",
    "        \n",
    "        'temporal_coverage': {\n",
    "            'records_per_day': len(self.sales_data) / ((self.sales_data['date'].max() - self.sales_data['date'].min()).days + 1),\n",
    "            'expected_records_per_day': self.sales_data['store_nbr'].nunique() * self.sales_data['family'].nunique(),\n",
    "            'coverage_ratio': None  # Will calculate below\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Calculate coverage ratio\n",
    "    expected_daily = quality_metrics['dataset_overview']['stores_count'] * quality_metrics['dataset_overview']['families_count']\n",
    "    quality_metrics['temporal_coverage']['coverage_ratio'] = quality_metrics['temporal_coverage']['records_per_day'] / expected_daily\n",
    "    \n",
    "    # Display key findings\n",
    "    print(f\"üìä Dataset Overview:\")\n",
    "    print(f\"   ‚Ä¢ Total records: {quality_metrics['dataset_overview']['total_records']:,}\")\n",
    "    print(f\"   ‚Ä¢ Date range: {quality_metrics['dataset_overview']['date_range']['total_days']} days\")\n",
    "    print(f\"   ‚Ä¢ Store-family combinations: {quality_metrics['dataset_overview']['unique_combinations']:,}\")\n",
    "    \n",
    "    print(f\"\\nüìà Data Quality:\")\n",
    "    print(f\"   ‚Ä¢ Zero sales: {quality_metrics['data_quality']['zero_sales_percentage']:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ Negative sales: {quality_metrics['data_quality']['negative_sales']:,} records\")\n",
    "    print(f\"   ‚Ä¢ Average daily sales: {quality_metrics['data_quality']['sales_statistics']['mean']:.2f}\")\n",
    "    print(f\"   ‚Ä¢ Coverage ratio: {quality_metrics['temporal_coverage']['coverage_ratio']:.3f}\")\n",
    "    \n",
    "    self.quality_metrics = quality_metrics\n",
    "    return quality_metrics\n",
    "\n",
    "# Add this method to the FavoritaDataExplorer class\n",
    "FavoritaDataExplorer.comprehensive_data_assessment = comprehensive_data_assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceae187",
   "metadata": {},
   "source": [
    "## 2. Comprehensive Data Explorer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "295388c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initialized FavoritaDataExplorer\n",
      "   Data path: data/raw/\n",
      "   Results path: results/\n"
     ]
    }
   ],
   "source": [
    "explorer = FavoritaDataExplorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c6a8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Loading Corporaci√≥n Favorita datasets...\n",
      "‚ùå Error loading datasets: [Errno 2] No such file or directory: 'data/raw//train.csv'\n",
      "üìã Expected files in data/raw/:\n",
      "   ‚Ä¢ train.csv (sales data)\n",
      "   ‚Ä¢ stores.csv (store metadata)\n",
      "   ‚Ä¢ oil.csv (oil prices)\n",
      "   ‚Ä¢ holidays_events.csv (holidays)\n",
      "‚ùå Check data files in data/raw/\n"
     ]
    }
   ],
   "source": [
    "if explorer.load_datasets():\n",
    "    print(\"‚úÖ Data loaded successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå Check data files in data/raw/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad488bb",
   "metadata": {},
   "source": [
    "## 3. Execute Comprehensive Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933e727",
   "metadata": {},
   "source": [
    "## 4. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69210a35",
   "metadata": {},
   "source": [
    "## 5. Store-Family Combination Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16f742",
   "metadata": {},
   "outputs": [],
   "source": "# Restart kernel and run this cell to verify Phase 1 completion\n\nprint(\"üéØ FINAL PHASE 1 VERIFICATION\")\nprint(\"=\" * 50)\n\nimport os\nimport sys\nsys.path.append('../src')\n\n# Check file existence\nfiles_to_check = {\n    'JSON evaluation cases': '../results/evaluation_cases.json',\n    'Production case manager': '../src/data/evaluation_cases.py',\n    'Data module init': '../src/data/__init__.py',\n    'Source package init': '../src/__init__.py'\n}\n\nall_files_exist = True\nfor name, filepath in files_to_check.items():\n    if os.path.exists(filepath):\n        size = os.path.getsize(filepath)\n        print(f\"‚úÖ {name}: {size:,} bytes\")\n    else:\n        print(f\"‚ùå Missing {name}: {filepath}\")\n        all_files_exist = False\n\n# Test production module\ntry:\n    from data.evaluation_cases import EvaluationCaseManager\n    \n    manager = EvaluationCaseManager()\n    cases = manager.get_cases_list()\n    metadata = manager.get_metadata()\n    \n    print(f\"\\n‚úÖ Production Module Test:\")\n    print(f\"   ‚Ä¢ Loaded {len(cases)} evaluation cases\")\n    print(f\"   ‚Ä¢ Manager initialized successfully\")\n    print(f\"   ‚Ä¢ Selection method: {metadata.get('selection_method', 'N/A')}\")\n    \n    # Fix the formatting issue by checking if value is numeric before applying comma formatting\n    total_candidates = metadata.get('total_candidates', 'N/A')\n    final_selected = metadata.get('final_selected', 'N/A')\n    \n    if isinstance(total_candidates, (int, float)):\n        print(f\"   ‚Ä¢ Total candidates: {total_candidates:,}\")\n    else:\n        print(f\"   ‚Ä¢ Total candidates: {total_candidates}\")\n        \n    if isinstance(final_selected, (int, float)):\n        print(f\"   ‚Ä¢ Final selected: {final_selected:,}\")\n    else:\n        print(f\"   ‚Ä¢ Final selected: {final_selected}\")\n    \n    if len(cases) == 10:\n        print(\"\\n‚úÖ PHASE 1 COMPLETE - All verification checks passed!\")\n    else:\n        print(\"\\n‚ö†Ô∏è  PHASE 1 NEEDS ATTENTION - Please resolve issues above\")\n        \nexcept Exception as e:\n    print(f\"‚ùå Production module test failed: {e}\")\n    print(\"‚ö†Ô∏è  PHASE 1 NEEDS ATTENTION - Please resolve issues above\")\n    all_files_exist = False"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "store_sales_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}